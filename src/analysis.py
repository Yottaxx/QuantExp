import torch
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from scipy.stats import spearmanr
from tqdm import tqdm
from .config import Config
from .model import PatchTSTForStock
from .data_provider import DataProvider


class BacktestAnalyzer:
    def __init__(self, start_date='2024-01-01', end_date='2025-12-31'):
        self.start_date = pd.to_datetime(start_date)
        self.end_date = pd.to_datetime(end_date)
        self.device = Config.DEVICE
        self.model_path = f"{Config.OUTPUT_DIR}/final_model"
        self.results_df = None

    def generate_historical_predictions(self):
        """
        å…¨é‡å†å²å›æº¯æ¨ç†
        é€»è¾‘ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯¹è¿‡å»æ¯ä¸€å¤©çš„å…¨å¸‚åœºè‚¡ç¥¨è¿›è¡Œæ‰“åˆ†
        """
        print("\n" + "=" * 60)
        print(">>> å¯åŠ¨å…¨é‡æˆªé¢åˆ†æ (Full Cross-Sectional Analysis)")
        print("=" * 60)

        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æœªæ‰¾åˆ°: {self.model_path}")
            return

        print(f"åŠ è½½æ¨¡å‹: {self.model_path}")
        model = PatchTSTForStock.from_pretrained(self.model_path).to(self.device)
        model.eval()

        # 1. åŠ è½½æ•°æ® (Train æ¨¡å¼ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦ Target/Label æ¥éªŒè¯æ•ˆæœ)
        # åˆ©ç”¨ç¼“å­˜åŠ é€Ÿ
        print("åŠ è½½å…¨å¸‚åœº Panel æ•°æ® (éªŒè¯æ¨¡å¼)...")
        panel_df, feature_cols = DataProvider.load_and_process_panel(mode='train')

        # 2. ç­›é€‰æ—¶é—´æ®µ (ä¸ºäº†å›æµ‹æ•ˆç‡ï¼Œåªå–ç›®æ ‡åŒºé—´ + çª—å£æœŸ)
        # é¢„ç•™è¶³å¤Ÿçš„ Lookback çª—å£
        start_buffer = self.start_date - pd.Timedelta(days=Config.CONTEXT_LEN * 2 + 100)
        mask_date = (panel_df['date'] >= start_buffer) & (panel_df['date'] <= self.end_date)
        df_sub = panel_df[mask_date].copy()

        if df_sub.empty:
            print("âŒ é€‰å®šåŒºé—´æ— æ•°æ®")
            return

        print("æ­£åœ¨æ„å»ºæ—¶åºçª—å£å¹¶æ¨ç†...")

        all_results = []
        batch_size = Config.ANALYSIS_BATCH_SIZE
        batch_inputs = []
        batch_meta = []  # (date, code, rank_label, excess_label)

        grouped = df_sub.groupby('code')

        # [Optim] ä½¿ç”¨ tqdm æ˜¾ç¤ºæ€»ä½“è¿›åº¦ï¼Œè€Œä¸æ˜¯æ¯åªè‚¡ç¥¨åˆ·å±
        for code, group in tqdm(grouped, desc="Processing Stocks"):
            if len(group) < Config.CONTEXT_LEN: continue

            # æå– Numpy æ•°ç»„ (Float32)
            feats = group[feature_cols].values.astype(np.float32)
            dates = group['date'].values

            # ä¼˜å…ˆè·å–é¢„è®¡ç®—å¥½çš„æ ‡ç­¾
            ranks = group['rank_label'].values if 'rank_label' in group.columns else np.zeros(len(group))
            excess = group['excess_label'].values if 'excess_label' in group.columns else group['target'].values

            seq_len = Config.CONTEXT_LEN

            # [Fix] ä¼˜åŒ–å¾ªç¯è¾¹ç•Œï¼Œç¡®ä¿ç´¢å¼•ä¸è¶Šç•Œ
            # æˆ‘ä»¬éœ€è¦ feats[i: i+seq_len] ä½œä¸ºè¾“å…¥
            # å¯¹åº”çš„é¢„æµ‹æ—¥æœŸæ˜¯ dates[i + seq_len - 1]
            valid_indices = range(len(group) - seq_len + 1)

            for i in valid_indices:
                pred_date_ts = dates[i + seq_len - 1]
                pred_date = pd.to_datetime(pred_date_ts)

                # åªä¿ç•™ç”¨æˆ·æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„ç»“æœ
                if pred_date < self.start_date or pred_date > self.end_date:
                    continue

                batch_inputs.append(feats[i: i + seq_len])
                batch_meta.append({
                    'date': pred_date,
                    'code': code,
                    'rank_label': ranks[i + seq_len - 1],
                    'excess_label': excess[i + seq_len - 1]
                })

                if len(batch_inputs) >= batch_size:
                    self._flush_batch(model, batch_inputs, batch_meta, all_results)
                    batch_inputs = []
                    batch_meta = []

        # å¤„ç†å‰©ä½™ Batch
        if batch_inputs:
            self._flush_batch(model, batch_inputs, batch_meta, all_results)

        self.results_df = pd.DataFrame(all_results)
        print(f"æ¨ç†å®Œæˆï¼Œç”Ÿæˆ {len(self.results_df)} æ¡é¢„æµ‹è®°å½•ã€‚")

    def _flush_batch(self, model, inputs, meta, results_list):
        tensor = torch.tensor(np.array(inputs), dtype=torch.float32).to(self.device)
        with torch.no_grad():
            outputs = model(past_values=tensor)
            scores = outputs.logits.squeeze().cpu().numpy()

        # Handle batch size 1 or scalar output
        if scores.ndim == 0: scores = [scores]
        if len(meta) > 1 and len(scores) != len(meta):
            # æå°‘æ•°æƒ…å†µä¸‹å¯èƒ½ç»´åº¦ä¸åŒ¹é…ï¼Œåšä¸ªé˜²å¾¡
            scores = np.resize(scores, len(meta))

        for i, score in enumerate(scores):
            # [Safe] ç¡®ä¿ meta ç´¢å¼•ä¸è¿‡ç•Œ
            if i >= len(meta): break
            item = meta[i]
            item['score'] = float(score)
            results_list.append(item)

    def analyze_performance(self):
        if self.results_df is None or self.results_df.empty:
            print("âš ï¸ æ— åˆ†æç»“æœæ•°æ®")
            return

        # æŒ‰æ—¥æœŸå’Œåˆ†æ•°æ’åº
        df = self.results_df.sort_values(['date', 'score'], ascending=[True, False])

        print("\nè®¡ç®—æˆªé¢ IC æŒ‡æ ‡...")

        # 1. è®¡ç®— Rank IC
        # [Fix] å…¼å®¹ Pandas æ–°ç‰ˆ groupby apply
        daily_ic = df.groupby('date')[['score', 'rank_label']].apply(
            lambda x: spearmanr(x['score'], x['rank_label'])[0]
        )

        ic_mean = daily_ic.mean()
        ic_std = daily_ic.std()
        icir = ic_mean / (ic_std + 1e-9) * np.sqrt(252)

        print("-" * 40)
        print(f"ğŸ“Š ã€å› å­ç»©æ•ˆæŠ¥å‘Šã€‘")
        print(f"Rank IC (Mean): {ic_mean:.4f}")
        print(f"ICIR (Annual) : {icir:.4f}")
        print(f"IC Win Rate   : {(daily_ic > 0).mean():.2%}")
        print("-" * 40)

        # 2. åˆ†å±‚å›æµ‹ (Layered Backtest)
        def get_layer_ret(g):
            try:
                # å°è¯•åˆ†5ç»„
                g['group'] = pd.qcut(g['score'], 5, labels=False, duplicates='drop')
                return g.groupby('group')['excess_label'].mean()
            except:
                return None

        # [Fix] å…¼å®¹ Pandas æ–°ç‰ˆ
        layer_ret_raw = df.groupby('date').apply(get_layer_ret)

        if layer_ret_raw is not None and not layer_ret_raw.empty:
            if isinstance(layer_ret_raw, pd.Series):
                layer_ret = layer_ret_raw.unstack(level=-1)
            else:
                layer_ret = layer_ret_raw

            layer_ret = layer_ret.fillna(0.0)

            # ==================================================================
            # [CRITICAL FIX] ä¿®æ­£é‡å æ”¶ç›Šè®¡ç®—é€»è¾‘
            # ==================================================================
            # å› ä¸º Config.PRED_LEN = 5ï¼Œä¹Ÿå°±æ˜¯è¯´ excess_label æ˜¯æœªæ¥5å¤©çš„ç´¯è®¡æ”¶ç›Šã€‚
            # å¦‚æœæ¯å¤©éƒ½ç´¯ä¹˜è¿™ä¸ªæ”¶ç›Šï¼Œä¼šå¯¼è‡´æ”¶ç›Šè¢«é‡å¤è®¡ç®— 5 æ¬¡ã€‚
            #
            # ä¿®æ­£æ–¹æ³•ï¼š
            # å°† N æ—¥ç´¯è®¡æ”¶ç›Šå¹³æ‘Šåˆ°å•æ—¥ï¼Œè¿‘ä¼¼ä¸ºï¼šDaily_Ret = Total_Ret / N
            # è¿™æ˜¯ä¸€ä¸ªçº¿æ€§è¿‘ä¼¼ï¼Œç”¨äºåˆ†å±‚å¯¹æ¯”è¶³å¤Ÿäº†ã€‚ä¸¥è°¨çš„å›æµ‹è¯·å‚è€ƒ backtest.pyã€‚
            # ==================================================================
            if Config.PRED_LEN > 1:
                print(f"âš ï¸ æ£€æµ‹åˆ°å¤šæ—¥é¢„æµ‹ (PRED_LEN={Config.PRED_LEN})ï¼Œæ­£åœ¨å¯¹æ”¶ç›Šç‡è¿›è¡Œå¹³æ‘Šä¿®æ­£...")
                layer_ret = layer_ret / Config.PRED_LEN

            # è®¡ç®—å„ç»„ç´¯ç§¯æ”¶ç›Š
            cum_ret = (1 + layer_ret).cumprod()

            plt.figure(figsize=(14, 8))

            # å­å›¾1: åˆ†å±‚æ”¶ç›Šæ›²çº¿
            plt.subplot(2, 1, 1)

            # è·å–å®é™…å­˜åœ¨çš„ç»„å·
            available_groups = sorted(layer_ret.columns)

            # é¢œè‰²æ˜ å°„ï¼šæ ¹æ®ç»„æ•°åŠ¨æ€ç”Ÿæˆæˆ–å›ºå®š
            cmap = plt.get_cmap('RdYlGn_r')  # çº¢(å¥½) -> ç»¿(å·®)

            for idx, i in enumerate(available_groups):
                # åŠ¨æ€ç”Ÿæˆæ ‡ç­¾
                if i == available_groups[-1]:
                    label = "Top Group (Long)"
                    c = 'red'
                    alpha = 1.0
                    lw = 2
                elif i == available_groups[0]:
                    label = "Bottom Group (Short)"
                    c = 'green'
                    alpha = 1.0
                    lw = 1.5
                else:
                    label = f"Group {i}"
                    c = 'grey'
                    alpha = 0.3
                    lw = 1

                plt.plot(cum_ret.index, cum_ret[i], label=label, color=c, alpha=alpha, linewidth=lw)

            # åŠ¨æ€è®¡ç®—å¤šç©ºæ›²çº¿
            if len(available_groups) >= 2:
                top_grp = available_groups[-1]
                bot_grp = available_groups[0]
                # å¤šç©ºæ”¶ç›Šä¹Ÿéœ€è¦å¹³æ‘Šå—ï¼Ÿæ˜¯çš„ï¼Œå› ä¸º layer_ret å·²ç»å¹³æ‘Šè¿‡äº†ï¼Œç›´æ¥ç›¸å‡å³å¯
                long_short_ret = layer_ret[top_grp] - layer_ret[bot_grp]
                long_short_cum = (1 + long_short_ret).cumprod()
                plt.plot(long_short_cum.index, long_short_cum, label='Long-Short (Alpha)', color='blue', linestyle='--',
                         linewidth=2)

            plt.title(f'Layered Backtest (Avg Daily Return derived from {Config.PRED_LEN}-Day Horizon)')
            plt.legend(loc='upper left')
            plt.grid(True, alpha=0.3)

            # å­å›¾2: æ¯æ—¥ IC æŸ±çŠ¶å›¾
            plt.subplot(2, 1, 2)
            plt.bar(daily_ic.index, daily_ic.values, color='orange', alpha=0.5, label='Daily IC')
            plt.axhline(ic_mean, color='red', linestyle='--', label=f'Mean IC: {ic_mean:.3f}')
            plt.title('Daily Rank IC Series')
            plt.legend()

            save_path = os.path.join(Config.OUTPUT_DIR, "cross_section_analysis.png")
            plt.tight_layout()
            plt.savefig(save_path)
            print(f"ğŸ“ˆ æŠ¥è¡¨å·²ä¿å­˜: {save_path}")