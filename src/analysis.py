import torch
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from scipy.stats import spearmanr
from tqdm import tqdm
from .config import Config
from .model import PatchTSTForStock
from .data_provider import DataProvider


class BacktestAnalyzer:
    def __init__(self, start_date='2024-01-01', end_date='2025-12-31'):
        self.start_date = pd.to_datetime(start_date)
        self.end_date = pd.to_datetime(end_date)
        self.device = Config.DEVICE
        self.model_path = f"{Config.OUTPUT_DIR}/final_model"
        self.results_df = None

    def generate_historical_predictions(self):
        """
        å…¨é‡å›æº¯æ¨ç†ï¼š
        åŠ è½½å…¨å†å²æ•°æ®ï¼ŒæŒ‰æ—¥æœŸæ»šåŠ¨çš„å½¢å¼ï¼Œå¯¹æ¯ä¸€å¤©å…¨å¸‚åœºçš„è‚¡ç¥¨è¿›è¡Œæ‰“åˆ†ã€‚
        """
        print("\n" + "=" * 60)
        print(">>> å¯åŠ¨å…¨é‡æˆªé¢åˆ†æ (Full Cross-Sectional Analysis)")
        print("=" * 60)

        # 1. åŠ è½½æ¨¡å‹
        if not os.path.exists(self.model_path):
            print(f"âŒ æ¨¡å‹æœªæ‰¾åˆ°: {self.model_path}")
            return

        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
        model = PatchTSTForStock.from_pretrained(self.model_path).to(self.device)
        model.eval()

        # 2. åŠ è½½å…¨é‡ Panel æ•°æ®
        # ä½¿ç”¨ mode='train'ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦ Target (çœŸå®æ”¶ç›Š) æ¥è®¡ç®— ICï¼Œæ‰€ä»¥å‰”é™¤æœ€åå‡ å¤©æ—  Target çš„æ•°æ®æ˜¯æ­£ç¡®çš„
        print("æ­£åœ¨åŠ è½½å…¨å¸‚åœº Panel æ•°æ® (ç”¨äºéªŒè¯)...")
        panel_df, feature_cols = DataProvider.load_and_process_panel(mode='train')

        # 3. æ—¶é—´è¿‡æ»¤
        mask = (panel_df['date'] >= self.start_date) & (panel_df['date'] <= self.end_date)
        df_sub = panel_df[mask].copy()

        if df_sub.empty:
            print("âŒ æ‰€é€‰æ—¶é—´æ®µæ— æ•°æ®")
            return

        print(f"åˆ†æåŒºé—´: {self.start_date.date()} ~ {self.end_date.date()}")
        print(f"æ ·æœ¬æ•°é‡: {len(df_sub)} è¡Œ")

        # 4. æŒ‰æ—¥æœŸåˆ†ç»„è¿›è¡Œæ‰¹é‡æ¨ç†
        # è¿™æ ·å¯ä»¥æ¨¡æ‹Ÿæ¯å¤©â€œé¢å¯¹å…¨å¸‚åœºè‚¡ç¥¨â€çš„é€‰è‚¡åœºæ™¯
        date_groups = df_sub.groupby('date')

        predictions = []

        print("æ­£åœ¨è¿›è¡Œå†å²å›æº¯æ¨ç†...")
        with torch.no_grad():
            for date, group in tqdm(date_groups, desc="Daily Inference"):
                # è·³è¿‡æ ·æœ¬å¤ªå°‘çš„æ—¥æœŸ
                if len(group) < 10: continue

                # æ£€æŸ¥æ¯åªè‚¡ç¥¨æ˜¯å¦æœ‰è¶³å¤Ÿå†å²çª—å£
                # ä¸ºäº†é€Ÿåº¦ï¼Œè¿™é‡Œå‡è®¾ DataProvider å·²ç»ä¿è¯äº†å‰é¢æœ‰è¶³å¤Ÿçš„æ•°æ®å¡«å……
                # ä¸¥è°¨çš„åšæ³•æ˜¯å»åŸå§‹ panel_df é‡Œæ‰¾å‰ 30 å¤©

                # æˆ‘ä»¬éœ€è¦æ„å»º tensor: [Batch, Seq_Len, Features]
                # è¿™é‡Œæœ‰ä¸€ä¸ªéš¾ç‚¹ï¼šdf_sub åˆ‡ç‰‡å¯èƒ½å¯¼è‡´æ— æ³•è·å–å‰åºçª—å£
                # ä¼˜åŒ–æ–¹æ¡ˆï¼šæˆ‘ä»¬ç›´æ¥éå† panel_dfï¼Œä½†åªåœ¨ç›®æ ‡æ—¥æœŸè¾“å‡ºç»“æœ

                pass  # é€»è¾‘ä¼˜åŒ–è§ä¸‹æ–‡

        # --- ä¼˜åŒ–åçš„æ¨ç†é€»è¾‘ ---
        # ç›´æ¥åˆ©ç”¨ panel_df çš„è¿ç»­æ€§

        results = []
        unique_dates = df_sub['date'].unique()

        # é¢„å¤„ç†ï¼šå°† panel_df è®¾ä¸º (code, date) ç´¢å¼•ä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾çª—å£
        # ä½†ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬é‡‡ç”¨â€œæ»‘åŠ¨çª—å£ç”Ÿæˆå™¨â€æ¨¡å¼

        # å®é™…ä¸Šï¼Œä¸ºäº†ç®€åŒ–ä»£ç å¹¶ä¿è¯å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥åˆ©ç”¨ 'code' group
        # å¯¹æ¯åªè‚¡ç¥¨ï¼Œæ‰¾å‡ºå®ƒåœ¨åˆ†æåŒºé—´å†…çš„æ‰€æœ‰æ—¶é—´ç‚¹

        # æ›´åŠ å·¥ç¨‹åŒ–çš„åšæ³•ï¼š
        # æˆ‘ä»¬å¤ç”¨ DataProvider çš„é€»è¾‘ï¼Œä½†è¿™æ¬¡æˆ‘ä»¬è¦è®°å½•é¢„æµ‹å€¼å’ŒçœŸå®å€¼

        # è®©æˆ‘ä»¬ç”¨ä¸€ç§æ›´ç›´æ¥çš„æ–¹æ³•ï¼š
        # éå†æ‰€æœ‰è‚¡ç¥¨ï¼Œç”Ÿæˆ Tensorï¼Œé¢„æµ‹ï¼Œç„¶åæŠŠç»“æœæ‹¼å›å»

        codes = df_sub['code'].unique()

        # æå–ç‰¹å¾çŸ©é˜µå’Œ Target
        # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬ç®€åŒ–å¤„ç†ï¼Œç›´æ¥ç”¨å½“å‰è¡Œä½œä¸º Input (å‡è®¾å·²ç»åŒ…å«äº†æ—¶åºç‰¹å¾)
        # å®é™…ä¸Š PatchTST éœ€è¦ [Batch, 30, F]

        # é‡æ–°åˆ©ç”¨ groupby code
        full_grouped = panel_df.groupby('code')

        batch_inputs = []
        batch_metas = []  # (date, code, target)

        print("æ­£åœ¨æ„å»ºæ—¶åºçª—å£...")
        for code, group in tqdm(full_grouped, desc="Windowing"):
            # ç­›é€‰è¯¥è‚¡ç¥¨åœ¨å›æµ‹åŒºé—´å†…çš„æ•°æ®
            in_range_indices = group[(group['date'] >= self.start_date) & (group['date'] <= self.end_date)].index

            for idx in in_range_indices:
                # è·å–è¡Œå·ä½ç½®
                loc = group.index.get_loc(idx)

                # å¦‚æœå‰é¢æ²¡æœ‰è¶³å¤Ÿ 30 å¤©æ•°æ®ï¼Œè·³è¿‡
                if loc < Config.CONTEXT_LEN: continue

                # æˆªå–çª—å£ [loc-30 : loc]
                # æ³¨æ„ï¼šiloc åˆ‡ç‰‡æ˜¯å·¦é—­å³å¼€ï¼Œæ‰€ä»¥æ˜¯ loc-Context_Len : loc
                # ä½†æˆ‘ä»¬éœ€è¦åŒ…å« loc è¿™ä¸€å¤©çš„æ•°æ®ä½œä¸ºè¾“å…¥åºåˆ—çš„æœ€åä¸€å¤©å—ï¼Ÿ
                # PatchTST çš„è¾“å…¥æ˜¯ Past Valuesã€‚
                # å‡è®¾æˆ‘ä»¬è¦é¢„æµ‹ T+1ï¼Œæˆ‘ä»¬è¾“å…¥ T-29 ~ Tã€‚
                # è¿™é‡Œçš„ idx å°±æ˜¯ Tã€‚

                window = group.iloc[loc - Config.CONTEXT_LEN + 1: loc + 1]
                if len(window) != Config.CONTEXT_LEN: continue

                feature_val = window[feature_cols].values.astype(np.float32)

                target_val = group.loc[idx, 'excess_label']  # ä½¿ç”¨è¶…é¢æ”¶ç›Šä½œä¸ºéªŒè¯ç›®æ ‡
                if pd.isna(target_val): target_val = group.loc[idx, 'target']

                batch_inputs.append(feature_val)
                batch_metas.append({
                    'date': group.loc[idx, 'date'],
                    'code': code,
                    'label': target_val
                })

                # æ˜¾å­˜æ§åˆ¶ï¼šæ¯ 2048 ä¸ªæ ·æœ¬æ¨ä¸€æ¬¡
                if len(batch_inputs) >= 2048:
                    self._run_batch(model, batch_inputs, batch_metas, results)
                    batch_inputs = []
                    batch_metas = []

        # å¤„ç†å‰©ä½™çš„
        if batch_inputs:
            self._run_batch(model, batch_inputs, batch_metas, results)

        self.results_df = pd.DataFrame(results)
        print(f"æ¨ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(self.results_df)} æ¡é¢„æµ‹è®°å½•ã€‚")

    def _run_batch(self, model, inputs, metas, results_list):
        tensor = torch.tensor(np.array(inputs), dtype=torch.float32).to(self.device)
        scores = model(past_values=tensor).logits.squeeze().detach().cpu().numpy()
        if scores.ndim == 0: scores = [scores]

        for i, score in enumerate(scores):
            rec = metas[i]
            rec['score'] = float(score)
            results_list.append(rec)

    def analyze_performance(self):
        """
        æ ¸å¿ƒï¼šè®¡ç®— IC, ICIR, åˆ†å±‚æ”¶ç›Š
        """
        if self.results_df is None or self.results_df.empty:
            print("âŒ æ— é¢„æµ‹æ•°æ®")
            return

        df = self.results_df.sort_values(['date', 'score'], ascending=[True, False])

        print("\næ­£åœ¨è®¡ç®—æˆªé¢ç»©æ•ˆæŒ‡æ ‡...")

        # 1. Rank IC (ç›¸å…³æ€§)
        # æ¯å¤©è®¡ç®— é¢„æµ‹åˆ†(score) å’Œ çœŸå®ä¸‹æœŸæ”¶ç›Š(label) çš„ Spearman ç›¸å…³ç³»æ•°
        daily_ic = df.groupby('date').apply(
            lambda x: spearmanr(x['score'], x['label'])[0]
        )

        ic_mean = daily_ic.mean()
        ic_std = daily_ic.std()
        icir = ic_mean / (ic_std + 1e-9) * np.sqrt(252)  # å¹´åŒ– ICIR

        print("-" * 40)
        print(f"ğŸ“Š ã€å› å­ç»©æ•ˆæŠ¥å‘Š (IC Analysis)ã€‘")
        print("-" * 40)
        print(f"Rank IC (å‡å€¼) : {ic_mean:.4f} (æ ‡å‡†: >0.05 ä¼˜ç§€)")
        print(f"ICIR (å¹´åŒ–)    : {icir:.4f}   (æ ‡å‡†: >3.0 ä¼˜ç§€)")
        print(f"IC èƒœç‡        : {(daily_ic > 0).mean():.2%}")
        print("-" * 40)

        # 2. åˆ†å±‚å›æµ‹ (Layered Backtest)
        # æ¯å¤©æŠŠè‚¡ç¥¨åˆ†æˆ 5 ç»„ (Quintiles)
        def get_layer_ret(g):
            # qcut å¯èƒ½ä¼šå› ä¸ºæ•°æ®å°‘æŠ¥é”™ï¼Œç”¨ numpy split
            try:
                # æŒ‰åˆ†æ•°é™åºï¼Œåˆ†ä¸º 5 ç»„
                # 0: Top (åˆ†æ•°æœ€é«˜), 4: Bottom (åˆ†æ•°æœ€ä½)
                labels = pd.qcut(g['score'], 5, labels=False, duplicates='drop')
                # qcut é»˜è®¤æ˜¯å‡åº (0æ˜¯æœ€å°)ï¼Œæˆ‘ä»¬éœ€è¦åè¿‡æ¥æˆ–è€…æ³¨æ„ä¸€ä¸‹
                # score è¶Šå¤§è¶Šå¥½ï¼Œæ‰€ä»¥ qcut ç»“æœ 4 æ˜¯ Topï¼Œ0 æ˜¯ Bottom
                g['group'] = labels
                return g.groupby('group')['label'].mean()
            except:
                return None

        layer_ret = df.groupby('date').apply(get_layer_ret)

        # layer_ret åˆ—åæ˜¯ 0,1,2,3,4ã€‚å…¶ä¸­ 4 æ˜¯é«˜åˆ†å±‚(Top)ï¼Œ0 æ˜¯ä½åˆ†å±‚(Bottom)
        # è®¡ç®—ç´¯ç§¯æ”¶ç›Š
        cum_ret = (1 + layer_ret).cumprod()

        # å¤šç©ºæ”¶ç›Š (Top - Bottom)
        long_short = (1 + (layer_ret[4] - layer_ret[0])).cumprod()

        # 3. ç»˜å›¾
        plt.figure(figsize=(14, 8))

        plt.subplot(2, 1, 1)
        for i in range(5):
            label = "Top 20% (Long)" if i == 4 else f"Group {i}"
            label = "Bottom 20% (Short)" if i == 0 else label
            color = 'red' if i == 4 else 'green' if i == 0 else 'grey'
            alpha = 1.0 if i in [0, 4] else 0.3
            plt.plot(cum_ret.index, cum_ret[i], label=label, color=color, alpha=alpha)

        plt.plot(long_short.index, long_short, label='Long-Short (Alpha)', color='blue', linestyle='--', linewidth=2)
        plt.title('Layered Backtest (Cumulative Excess Return)')
        plt.legend(loc='upper left')
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 1, 2)
        plt.bar(daily_ic.index, daily_ic.values, color='orange', alpha=0.5, label='Daily IC')
        plt.axhline(daily_ic.mean(), color='red', linestyle='--', label=f'Mean IC: {ic_mean:.3f}')
        plt.title('Daily Rank IC Series')
        plt.legend()
        plt.grid(True, alpha=0.3)

        save_path = os.path.join(Config.OUTPUT_DIR, "cross_section_analysis.png")
        plt.tight_layout()
        plt.savefig(save_path)
        print(f"ğŸ“ˆ æˆªé¢åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")